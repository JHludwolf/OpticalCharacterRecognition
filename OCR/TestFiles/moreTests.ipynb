{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "import pytesseract\n",
    "from pytesseract import image_to_string\n",
    "#pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_obj = Image.open(\"../tests/test02.png\")\n",
    "rgb = cv2.imread('../tests/test02.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = cv2.cvtColor(rgb, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#threshold the image\n",
    "_, bw = cv2.threshold(small, 0.0, 255.0, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "\n",
    "# get horizontal mask of large size since text are horizontal components\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 1))\n",
    "connected = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# find all the contours\n",
    "contours, hierarchy,=cv2.findContours(connected.copy(),cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', '', '', 'ciudad \\n', 'estado \\n', 'Significar\\n', '', 'tambien\\n', 'politeuma\\n', '', '', 'griego\\n', '', '', '', '', '', '', '', 'politeia\\n', '', 'totalmente\\n', '', '', 'pero\\n', 'je\\n', '', '', '', 'comoda\\n', 'traduccion\\n', '', '', 'Constitucion\\n', '', 'apunta\\n', '', '', 'obra\\n', '', 'de\\n', 'traductor\\n', '', '', 'espanol\\n', 'el\\n', '', '', '', '', '', 'los\\n', '', '', 'La\\n', '', '', 'constitucion\\n', '', 'iCUAL ES EL OBJETO DE SUS\\n\\nREFLEXIONES\\n\\n']\n"
     ]
    }
   ],
   "source": [
    "#Segment the text lines\n",
    "counter=0\n",
    "array_of_texts=[]\n",
    "for idx in range(len(contours)):\n",
    "    x, y, w, h = cv2.boundingRect(contours[idx])\n",
    "    cropped_image = image_obj.crop((x-10, y, x+w+10, y+h ))\n",
    "    str_store = re.sub(r'([^\\s\\w]|_)+', '', image_to_string(cropped_image))\n",
    "    array_of_texts.append(str_store)\n",
    "    counter+=1\n",
    "\n",
    "print(array_of_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Create MSER object\n",
    "mser = cv2.MSER_create()\n",
    "\n",
    "#Your image path i-e receipt path\n",
    "img = cv2.imread('../tests/test10.png')\n",
    "\n",
    "#Convert to gray scale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "vis = img.copy()\n",
    "\n",
    "#detect regions in gray scale image\n",
    "regions, _ = mser.detectRegions(gray)\n",
    "\n",
    "hulls = [cv2.convexHull(p.reshape(-1, 1, 2)) for p in regions]\n",
    "\n",
    "cv2.polylines(vis, hulls, 1, (0, 255, 0))\n",
    "\n",
    "cv2.imshow('img', vis)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "mask = np.zeros((img.shape[0], img.shape[1], 1), dtype=np.uint8)\n",
    "\n",
    "for contour in hulls:\n",
    "\n",
    "    cv2.drawContours(mask, [contour], -1, (255, 255, 255), -1)\n",
    "\n",
    "#this is used to find only text regions, remaining are ignored\n",
    "text_only = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "cv2.imshow(\"text only\", text_only)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/thresh.cpp:1555: error: (-2:Unspecified error) in function 'double cv::threshold(cv::InputArray, cv::OutputArray, double, double, int)'\n> THRESH_OTSU mode:\n>     'src_type == CV_8UC1 || src_type == CV_16UC1'\n> where\n>     'src_type' is 16 (CV_8UC3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5d6c037c2577>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#binarising the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mim_gray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../tests/test01.jpeg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_bw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_OTSU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mim_bw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.5) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/thresh.cpp:1555: error: (-2:Unspecified error) in function 'double cv::threshold(cv::InputArray, cv::OutputArray, double, double, int)'\n> THRESH_OTSU mode:\n>     'src_type == CV_8UC1 || src_type == CV_16UC1'\n> where\n>     'src_type' is 16 (CV_8UC3)\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img =cv.imread('../tests/test01.jpeg')\n",
    "#image scaling\n",
    "im = Image.open('../tests/test01.jpeg')\n",
    "#im.save(\"test-300.png\", dpi=(300,300))\n",
    "\n",
    "#image increase contrast/brightness\n",
    "alpha = 1.5 # Contrast control (1.0-3.0)\n",
    "beta = 0 # Brightness control (0-100)\n",
    "adjusted = cv.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "\n",
    "#binarising the image\n",
    "im_gray = cv.imread('../tests/test01.jpeg', cv.IMREAD_GRAYSCALE)\n",
    "(thresh, im_bw) = cv.threshold(img, 128, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n",
    "im_bw = cv.threshold(im_gray, thresh, 255, cv.THRESH_BINARY)[1]\n",
    "\n",
    "#image noise removal\n",
    "im_nr = cv.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 15)\n",
    "\n",
    "#skew correction\n",
    "def deskew(image):\n",
    "    coords = np.column_stack(np.where(image > 0))\n",
    "    angle = cv.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv.warpAffine(image, M, (w, h), flags=cv.INTER_CUBIC, borderMode=cv.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "img_ds=deskew(img)\n",
    "\n",
    "plt.imshow(img_ds)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c80a7e3a2de4dde693dabf38008612d40fcac8e48a425c55413d53e2fda1a28"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
